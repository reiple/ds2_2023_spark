{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "w7vEtFCjXxJl"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Graph"
      ],
      "metadata": {
        "id": "0W-T2Xk4WP_P"
      },
      "id": "0W-T2Xk4WP_P"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 환경설정"
      ],
      "metadata": {
        "id": "w7vEtFCjXxJl"
      },
      "id": "w7vEtFCjXxJl"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.4/spark-3.2.4-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.4-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark graphframes"
      ],
      "metadata": {
        "id": "27coPXAgfNit"
      },
      "id": "27coPXAgfNit",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init(\"/content/spark-3.2.4-bin-hadoop3.2\")"
      ],
      "metadata": {
        "id": "1xkk5rDXfPTW"
      },
      "id": "1xkk5rDXfPTW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "            .config(\"spark.driver.memory\", \"8g\")\\\n",
        "            .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.2-s_2.12\")\\\n",
        "            .getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "zgaqFPn3fQxJ"
      },
      "id": "zgaqFPn3fQxJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "gpath = '/gdrive/MyDrive/data/'"
      ],
      "metadata": {
        "id": "IkoPr8GDfSfJ"
      },
      "id": "IkoPr8GDfSfJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "senior-portsmouth"
      },
      "source": [
        "from pyspark.sql.functions import col, lit, when\n",
        "from graphframes import *\n",
        "import networkx as nx\n",
        "import matplotlib.pylab as plt"
      ],
      "id": "senior-portsmouth",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opened-cliff"
      },
      "source": [
        "## Pagerank"
      ],
      "id": "opened-cliff"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "considered-philippines"
      },
      "source": [
        "# Create a Vertex DataFrame with unique ID column \"id\"\n",
        "v = spark.createDataFrame([\n",
        "  (\"a\", \"Alice\", 34),\n",
        "  (\"b\", \"Bob\", 36),\n",
        "  (\"c\", \"Charlie\", 30),\n",
        "], [\"id\", \"name\", \"age\"])\n",
        "\n",
        "# Create an Edge DataFrame with \"src\" and \"dst\" columns\n",
        "e = spark.createDataFrame([\n",
        "  (\"a\", \"b\", \"friend\"),\n",
        "  (\"b\", \"c\", \"follow\"),\n",
        "  (\"c\", \"b\", \"follow\"),\n",
        "], [\"src\", \"dst\", \"relationship\"])\n",
        "\n",
        "# Create a GraphFrame\n",
        "g = GraphFrame(v, e)"
      ],
      "id": "considered-philippines",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hispanic-gazette"
      },
      "source": [
        "def PlotGraph(edge_list, figsize_=(8,5)):\n",
        "    Gplot=nx.DiGraph()\n",
        "    for row in edge_list.select('src','dst').collect():\n",
        "        Gplot.add_edge(row['src'],row['dst'])\n",
        "\n",
        "    plt.figure(figsize=figsize_)\n",
        "    plt.subplot(121)\n",
        "    nx.draw(Gplot, with_labels=True, font_weight='bold')"
      ],
      "id": "hispanic-gazette",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anticipated-summit"
      },
      "source": [
        "PlotGraph(g.edges)"
      ],
      "id": "anticipated-summit",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alert-roller"
      },
      "source": [
        "g.inDegrees.show()"
      ],
      "id": "alert-roller",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "related-emperor"
      },
      "source": [
        "g.outDegrees.show()"
      ],
      "id": "related-emperor",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shared-cameroon"
      },
      "source": [
        "# Run PageRank algorithm, and show results.\n",
        "results = g.pageRank(resetProbability=0.15, maxIter=5)\n",
        "results.vertices.select(\"id\", \"pagerank\").show()"
      ],
      "id": "shared-cameroon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moderate-corner"
      },
      "source": [
        "## 예제 : Citation network"
      ],
      "id": "moderate-corner"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alike-dakota"
      },
      "source": [
        "# load data\n",
        "nodeDF = spark.read.option('header', 'false') \\\n",
        "                .csv(gpath+'citeseer.node_labels') \\\n",
        "                .toDF(\"id\", \"label\")\n",
        "\n",
        "nodeDF.show()"
      ],
      "id": "alike-dakota",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "played-blocking"
      },
      "source": [
        "edgeDF = spark.read.option('header', 'false') \\\n",
        "                .csv(gpath+'citeseer.edges') \\\n",
        "                .toDF(\"src\", \"dst\", \"_\")\n",
        "\n",
        "edgeDF.show()"
      ],
      "id": "played-blocking",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exciting-gnome"
      },
      "source": [
        "v = nodeDF.select('id')\n",
        "e = edgeDF.select('src', 'dst')\n",
        "\n",
        "# Create a GraphFrame\n",
        "g = GraphFrame(v, e)"
      ],
      "id": "exciting-gnome",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "historical-defense"
      },
      "source": [
        "g.inDegrees.sort(col(\"inDegree\").desc()).show(5)"
      ],
      "id": "historical-defense",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "floral-stress"
      },
      "source": [
        "g.outDegrees.sort(col(\"outDegree\").desc()).show(5)"
      ],
      "id": "floral-stress",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prerequisite-republican"
      },
      "source": [
        "results = g.pageRank(resetProbability=0.15, maxIter=5)\n",
        "results.vertices.select(\"id\", \"pagerank\").sort(col(\"pagerank\").desc()).show(5)"
      ],
      "id": "prerequisite-republican",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "welsh-spirit"
      },
      "source": [
        "## 도전과제 : dolphins.csv"
      ],
      "id": "welsh-spirit"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fundamental-mystery"
      },
      "source": [
        "filename = 'dolphins.csv'\n",
        "\n",
        "# load data\n",
        "dolphinDF = spark.read.option('header', 'false') \\\n",
        "                .csv(gpath+filename) \\\n",
        "                .toDF(\"src\", \"_\", \"dst\",\"_\")\n",
        "\n",
        "dolphinDF.show(5)"
      ],
      "id": "fundamental-mystery",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "objective-advance"
      },
      "source": [
        "# WRITE YOUR CODE HERE\n"
      ],
      "id": "objective-advance",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 도전과제 : lesmis.csv"
      ],
      "metadata": {
        "id": "BCo_oGpWXdug"
      },
      "id": "BCo_oGpWXdug"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "latin-gardening"
      },
      "source": [
        "filename = 'lesmis.csv'\n",
        "# load data\n",
        "lesmisDF = spark.read.option('header', 'false') \\\n",
        "                .csv(gpath+filename) \\\n",
        "                .toDF(\"src\", \"_\", \"dst\",\"_\")\n",
        "\n",
        "lesmisDF.show(5)"
      ],
      "id": "latin-gardening",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "secret-ethiopia"
      },
      "source": [
        "# WRITE YOUR CODE HERE\n"
      ],
      "id": "secret-ethiopia",
      "execution_count": null,
      "outputs": []
    }
  ]
}